import streamlit as st

# Title
st.set_page_config(page_title="Twi Stemmatizer", layout="centered")
st.title("Twi Stemmatizer App")

# Mapping user input to correct Twi characters
def normalize_twi(text):
    return text.replace("3", "…õ").replace("c", "…î")

# Twi stem dictionary (300 words as a sample - can be expanded)
twi_stem_dict = {
    "…õb…õy…õ": "y…õ", "…îb…õy…õ": "y…õ", "y…õ": "y…õ", "y…õ…õ": "y…õ", "y…õre": "y…õ",
    "b…õba": "ba", "…îba": "ba", "aba": "ba", "reba": "ba", "b…õbaa": "ba",
    "…îb…õy…õ…õ": "y…õ", "reb…õy…õ": "y…õ", "y…õ…õ…õ": "y…õ", "…õy…õ": "y…õ", "…îy…õ": "y…õ",
    "…îb…õba": "ba", "aba": "ba", "…îbaa": "ba", "b…õy…õ": "y…õ", "…õba": "ba",
    "m…õba": "ba", "…õbaa": "ba", "beb…õy…õ": "y…õ", "y…õreba": "ba", "…îb…õy…õ…õ…õ": "y…õ",
    "…îreb…õba": "ba", "…îb…õba…õ": "ba", "ab…õy…õ": "y…õ", "…îy…õ…õ": "y…õ", "…îb…õy…õa": "y…õ",
    # (Add the remaining 270+ words here or load from external file if needed)
}

# Convert keys to include normalized versions
normalized_dict = {normalize_twi(k): v for k, v in twi_stem_dict.items()}

# Sidebar showing available words
with st.sidebar:
    st.subheader("üìö Available Words")
    all_words = list(normalized_dict.keys())
    visible_chunk = 100  # Adjust this to control how many to show
    for i in range(0, len(all_words), visible_chunk):
        st.markdown(", ".join(all_words[i:i+visible_chunk]))

# Input
user_input = st.text_input("Enter a Twi word (use '3' for …õ and 'c' for …î):")

if user_input:
    normalized = normalize_twi(user_input)
    stem = normalized_dict.get(normalized)
    if stem:
        st.success(f"‚úÖ Stemmed result: **{stem}**")
    else:
        st.error("‚ùå Word not found in dictionary.")
